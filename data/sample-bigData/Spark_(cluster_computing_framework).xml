<?xml version="1.0" ?><page xmlns="http://www.mediawiki.org/xml/export-0.8/" version="0.8">
    <title>Spark (cluster computing framework)</title>
    <ns>0</ns>
    <id>37668259</id>
    <revision>
      <id>562331603</id>
      <parentid>561562417</parentid>
      <timestamp>2013-07-01T02:12:54Z</timestamp>
      <contributor>
        <ip>98.215.1.90</ip>
      </contributor>
      <text xml:space="preserve">{{ Infobox Software
| name                   = Spark
| logo                   = [[File:Spark-logo-192x100px.png|frameless|Spark Logo]]
| caption                =
| developer              = [[Apache Software Foundation]], [[UC Berkeley]] 
| status                 = Active
| latest release version = v0.7.2
| latest release date    = {{release date|2013|06|02}}
| latest preview version = 
| latest preview date    = 
| operating system       = [[Linux]], [[MAC OS]], [[Windows]]
| size                   = 
| programming language   = [[Scala (programming language)|Scala]], [[Java]], [[Python (programming language)|Python]]
| genre                  = data analytics, [[machine learning]] algorithms
| license                = [[BSD License]] 
| website                = http://www.spark-project.org/
}}

''Apache Spark'' is an open-source data analytics cluster computing framework originally developed in the AMPLab&lt;ref&gt;{{cite web|url=http://amplab.cs.berkeley.edu |title=AMPLab at the University of California, Berkeley |publisher=Amplab.cs.berkeley.edu |date= |accessdate=2013-03-05}}&lt;/ref&gt; at [[UC Berkeley]]. Spark fits into the Hadoop open-source community, building on top of the Hadoop Distributed File System (HDFS)&lt;ref&gt;[https://amplab.cs.berkeley.edu/software/ Figure showing Spark in relation to other open-source Software projects including Hadoop]&lt;/ref&gt;. However, Spark provides an easier to use alternative to Hadoop MapReduce and offers performance up to 100 times faster than previous generation systems like Hadoop MapReduce for certain applications&lt;ref&gt;{{cite paper|first1=Matei| last1=Zaharia| first2=Mosharaf |last2=Chowdhury| first3=Michael| last3=Franklin| first4=Scott| last4=Shenker| first5=Ion| last5=Stoica|title=Spark: Cluster Computing with Working Sets| conference=HotCloud 2010|date=June 2010| url=https://amplab.cs.berkeley.edu/publication/spark-cluster-computing-with-working-sets-paper/}}&lt;/ref&gt;. Spark provides primitives for in-memory cluster computing that allows user programs to load data into a cluster's memory and query it repeatedly, making it well suited to advanced Machine Learning algorithms&lt;ref&gt;{{cite AV media| url=http://www.youtube.com/watch?v=qLvLg-sqxKc| location=Invited Talk at NIPS 2011 Big Learning Workshop: Algorithms, Systems, and Tools for Learning at Scale
|people=Matei Zaharia|title=Spark: In-Memory Cluster Computing for Iterative and Interactive Applications}}&lt;/ref&gt;.

Spark is open-source&lt;ref&gt;[http://github.com/mesos/spark Spark open-source project page on Github.com]&lt;/ref&gt; and has received code contributions from large companies that use Spark including Yahoo! and Intel&lt;ref&gt;{{cite news| work=wired.com| title=Spark: Open Source Superstar Rewrites Future of Big Data| author= Cade Metz| date=June 19, 2013| url=http://www.wired.com/wiredenterprise/2013/06/yahoo-amazon-amplab-spark/all/}}&lt;/ref&gt; as well as small companies and startups such as Conviva&lt;ref&gt;{{cite blog| author=Dilip Joseph| date=December 27 2011| title=Using Spark and Hive to process BigData at Conviva|url=http://www.conviva.com/using-spark-and-hive-to-process-bigdata-at-conviva/}}&lt;/ref&gt;, Quantifind&lt;ref&gt;{{cite AV media| url=http://www.youtube.com/watch?v=DI81yppHI6w| people=Erich Nachbar| title=Running Spark In Production| location=Spark use-cases session at AMP Camp One Aug 2012, UC Berkeley}}&lt;/ref&gt;, ClearStory Data&lt;ref&gt;[http://strataconf.com/strata2013/public/schedule/detail/26743 Beyond Hadoop MapReduce: Interactive Analytic Insights Using Spark] - Abstract of talk given by ClearStory Data CEO Sharmila Shahani-Mulligan about using Spark&lt;/ref&gt;, Ooyala&lt;ref&gt;{{cite blog|title=Fast Spark Queries on In-Memory Datasets|author=Evan Chan|date=June 2013|url=http://engineering.ooyala.com/blog/fast-spark-queries-memory-datasets}}&lt;/ref&gt; and many more&lt;ref&gt;[http://andykonwinski.com/spark-and-shark-in-the-news/ Spark, Shark, and BDAS In the News]&lt;/ref&gt;. In addition to wide usage, by June 2013, over 65 individual developers had contributed code to Spark, representing 17 different companies&lt;ref&gt;[https://groups.google.com/d/msg/spark-users/yDdjpDlLtV0/ez6oQi-Ag8gJ Email from Spark creator Matei Zaharia to spark-users mailing list: Spark to join Apache software foundation]&lt;/ref&gt;. Spark was accepted as an Apache incubator project of the Apache Software Foundation in June 2013&lt;ref&gt;[http://mail-archives.apache.org/mod_mbox/incubator-general/201306.mbox/%3CCDE7B773.E9A48%25chris.a.mattmann%40jpl.nasa.gov%3E  Email thread archive: &amp;#91;RESULT&amp;#93; &amp;#91;VOTE&amp;#93; Apache Spark for the Incubator]&lt;/ref&gt;.

== Features and Benefits ==
* High level API in Java, Scala, and Python for easy manipulation of large datasets.
* Scales seamlessly to clusters with hundreds of machines.
* Ability to cache datasets in memory for interactive data analysis: extract a working set, cache it, query it repeatedly.
* Interactive command line interface (in Scala or Python) for low-latency data exploration at scale.
* As an example of the performance speedups associated with using memory, Matei Zaharia did a software demo&lt;ref&gt;{{cite AV media|title=Spark Demo|people=Matei Zaharia|url=http://www.youtube.com/watch?v=Jw9yNTJI8iM}}&lt;/ref&gt; in in which performed a full text search of all of the text in Wikipedia (i.e. which is more flexible than the text search capabilities on the Wikipedia website, since it is not using an index). When querying a copy of the full text of Wikipedia across a small cluster of computers. It took 20 seconds to load all of the data into memory during the first query and 0.5 seconds for subsequent queries of the-in memory data.

==External links==
* [http://spark-project.org Spark Homepage]
* [https://github.com/amplab/shark/wiki Shark] - A large-scale data warehouse system for Spark designed to be compatible with Apache Hive. It can execute Hive QL queries up to 100 times faster than Hive without any modification to the existing data or queries.
* [http://spark-project.org/docs/latest/streaming-programming-guide.html Spark Streaming] - A component of Spark that extends core Spark functionality to allow for real-time analysis of streaming data.

==References==
{{Reflist}}

[[Category:University of California, Berkeley]]
[[Category:Cluster computing]]</text>
      <sha1>is5mj5rcob50lrf4o553a934g6pvnwc</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>