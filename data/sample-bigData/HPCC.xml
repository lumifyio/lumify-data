<?xml version="1.0" ?><page xmlns="http://www.mediawiki.org/xml/export-0.8/" version="0.8">
    <title>HPCC</title>
    <ns>0</ns>
    <id>31552031</id>
    <revision>
      <id>544074796</id>
      <parentid>533428484</parentid>
      <timestamp>2013-03-14T11:54:08Z</timestamp>
      <contributor>
        <username>Abhilashsr</username>
        <id>13822241</id>
      </contributor>
      <text xml:space="preserve">{{Infobox software
| name                   = HPCC Platform
| caption                =
| developer              = HPCC Systems, LexisNexis Risk Solutions
| status                 = Active
| latest release version = 3.10
| operating system       = [[Linux]]
| programming language   = [[C++]], [[ECL,_data-centric_programming_language_for_Big_Data|ECL]]
| license                = [[Apache License]] 2.0
| website                = http://hpccsystems.com/
}}

'''HPCC''' (High-Performance Computing Cluster), also known as '''DAS''' (Data Analytics Supercomputer), is an open source [[data-intensive computing]] system platform developed by [[LexisNexis]] Risk Solutions.  The HPCC platform incorporates a [[software architecture]] implemented on [[Commodity_computing|commodity computing clusters]] to provide high-performance, data-parallel processing for applications utilizing [[Big data|Big Data]].  The HPCC platform includes system configurations to support both parallel batch data processing (Thor) and high-performance online query applications using indexed data files (Roxie).  The HPCC platform also includes a data-centric declarative programming language for parallel data processing called [[ECL, data-centric programming language for Big Data|ECL]].

== Introduction ==

Many organizations have large amounts of data which has been collected and stored in massive datasets which needs be processed and analyzed to provide business intelligence, improve products and services for customers, or to meet other internal data processing requirements.&lt;ref&gt;[http://www.springer.com/computer/communication+networks/book/978-1-4419-6523-3 Handbook of Cloud Computing], "Data-Intensive Technologies for Cloud Computing," by A.M. Middleton. Handbook of Cloud Computing. Springer, 2010.&lt;/ref&gt;  For example, Internet companies need to process data collected by [[Web crawler]]s as well as logs, click data, and other information generated by [[Web service]]s.  Parallel [[Relational model|relational database technology]] has not proven to be cost-effective or provide the high-performance needed to analyze massive amounts of data in a timely manner.&lt;ref&gt;"MapReduce: A Flexible Data Processing Tool," by J. Dean, and S. Ghemawat. Communications of the ACM, Vol. 53, No. 1, 2010.&lt;/ref&gt;&lt;ref&gt;"SCOPE: Easy and Efficient Parallel Processing of Massive Data Sets," by R. Chaiken, B. Jenkins, P.A. Larson, B. Ramsey, D. Shakib, S. Weaver, and J. Zhou. Proceedings of the VLDB Endowment, 2008.&lt;/ref&gt;&lt;ref&gt;"MapReduce and Parallel DBMSs: Friends or Foes?" by M. Stonebraker, D. Abadi, D.J. DeWitt, S. Madden, E. Paulson, A. Pavlo, and A. Rasin.  Communications of the ACM, Vol. 53, No. 1, 2010, pp. 64-71.&lt;/ref&gt;  As a result several organizations developed technology to utilize large clusters of commodity servers to provide high-performance computing capabilities for processing and analysis of massive datasets.  Clusters can consist of hundreds or even thousands of commodity machines connected using high-bandwidth networks. Examples of this type of cluster technology include [[Google]]â€™s [[MapReduce]],&lt;ref&gt;"MapReduce: Simplified Data Processing on Large Clusters," by J. Dean and S. Ghemawat. Proceedings of the Sixth Symposium on Operating Systems Design and Implementation (OSDI), 2004.&lt;/ref&gt; [[Apache Hadoop]],&lt;ref&gt;"Pro Hadoop," by J. Venner. Apress, 2009.&lt;/ref&gt;&lt;ref&gt;""Hadoop: The Definitive Guide," by T. White. O'Reilly Media Inc., 2009&lt;/ref&gt; [[Aster Data Systems]], [[Sector/Sphere]],&lt;ref&gt;"Data Mining Using High Performance Data Clouds: Experimental Studies Using Sector and Sphere," by R. Grossman, and Y. Gu. Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2008.&lt;/ref&gt; and LexisNexis HPCC platform.

== High Performance Computing ==

[[High-performance computing|High-Performance Computing]] (HPC) is used to describe computing environments which utilize supercomputers and computer clusters to address complex computational requirements, support applications with significant processing time requirements, or require processing of significant amounts of data.  Supercomputers have generally been associated with scientific research and compute-intensive types of problems, but more and more supercomputer technology is appropriate for both compute-intensive and data-intensive applications.  A new trend in supercomputer design for high-performance computing is using clusters of independent processors connected in parallel.&lt;ref&gt;"High Performance Cluster Computing," by R. Buyya. Prentice Hall, 1999&lt;/ref&gt;  Many computing problems are suitable for [[Parallel computing|parallelization]], often problems can be divided in a manner so that each independent processing node can work on a portion of the problem in parallel by simply dividing the data to be processed, and then combining the final processing results for each portion.   This type of parallelism is often referred to as [[Data parallelism|data-parallelism]], and data-parallel applications are a potential solution to petabyte scale data processing requirements.&lt;ref&gt;"A design Methodology for Data-Parallel Applications," by L.S. Nyland, J.F. Prins, A. Golderg, and P.H. Mills. IEEE Transactions on Software Engineering, Vol. 26, No. 4, 2000, pp. 293-314.&lt;/ref&gt;&lt;ref&gt;"The Terascale Challenge," by D. Ravichandran, P. Pantel, and E. Hovy. Proceedings of the KDD Workshop on Mining for and from the Semantic Web, 2004&lt;/ref&gt;  [[Data parallelism|Data-parallelism]] can be defined as a computation applied independently to each data item of a set of data which allows the degree of parallelism to be scaled with the volume of data.  The most important reason for developing data-parallel applications is the potential for scalable performance in high-performance computing, and may result in several orders of magnitude performance improvement.

== Commodity Computing Clusters ==

[[File:Fig1 Comm Cluster.jpg|thumb|right|Figure 1. Commodity Computing Cluster&lt;ref&gt;"Introduction to Hadoop," by O. O'Malley. 2008.&lt;/ref&gt;]]

&lt;span&gt; The resulting economies of scale in using multiple independent processing nodes for supercomputer design to address high-performance computing requirements led directly to the implementation of [[commodity computing]] clusters.  A [[computer cluster]] is a group of shared individual computers, linked by high-speed communications in a [[local area network]] topology using technology such as [[Ethernet|gigabit network switches]] or [[InfiniBand]], and incorporating system software which provides an integrated [[parallel processing]] environment for applications with the capability to divide processing among the nodes in the cluster.  Cluster configurations can not only improve the performance of applications which use a single computer, but provide higher availability and reliability, and are typically much more cost-effective than single supercomputer systems with equivalent performance.  The key to the capability, performance, and throughput of a computing cluster is the system software and tools used to provide the parallel job execution environment.  [[Programming language]]s with [[Implicit parallelism|implicit parallel]] processing features and a high-degree of optimization are also needed to ensure high-performance results as well as high programmer productivity.  Clusters allow the data used by an application to be partitioned among the available computing resources and processed independently to achieve performance and scalability based on the amount of data.&lt;/span&gt;

&lt;span&gt;Commodity computing clusters are configured using commercial off-the-shelf (COTS) PC components. Rack-mounted servers or blade servers each with local memory and disk storage are often used as processing nodes to allow high-density small footprint configurations which facilitate the use of very high-speed communications equipment to connect the nodes (Figure 1).  Linux is widely used as the operating system for computer clusters.&lt;ref&gt;"Linux Clustering: Building and Maintaining Linux Clusters," by C. Bookman. New Riders Publishing, 2003&lt;/ref&gt;&lt;ref&gt;"High Performance Linux Clusters," by J.D. Sloan. O'Reilly Media Inc, 2005&lt;/ref&gt;&lt;/span&gt;{{-}}

== HPCC System Architecture ==

[[File:Fig2 Thor Cluster.jpg|thumb|right|Figure 2. Thor Processing Cluster.]]
 
The HPCC system architecture includes two distinct cluster processing environments, each of which can be optimized independently for its parallel data processing purpose.  The first of these platforms is called a Data Refinery whose overall purpose is the general processing of massive volumes of raw data of any type for any purpose but typically used for data cleansing and hygiene, [[Extract, transform, load|ETL]] processing of the raw data, record linking and entity resolution, large-scale ad-hoc complex analytics, and creation of keyed data and indexes to support high-performance structured queries and data warehouse applications.  The Data Refinery is also referred to as [[Thor]], a reference to the mythical Norse god of thunder with the large hammer symbolic of crushing large amounts of raw data into useful information.  A Thor cluster is similar in its function, execution environment, filesystem, and capabilities to the Google and Hadoop MapReduce platforms.

Figure 2 shows a representation of a physical Thor processing cluster which functions as a batch job execution engine for scalable data-intensive computing applications.  In addition to the Thor master and slave nodes, additional auxiliary and common components are needed to implement a complete HPCC processing environment.

[[File:Fig3 Roxie Cluster.jpg|thumb|left|Figure 3. Roxie Processing Cluster.]] 

The second of the parallel data processing platforms is called Roxie and functions as a rapid data delivery engine. This platform is designed as an online high-performance structured query and analysis platform or data warehouse delivering the parallel data access processing requirements of online applications through Web services interfaces supporting thousands of simultaneous queries and users with sub-second response times.  Roxie utilizes a [[Distributed file system|distributed indexed filesystem]] to provide parallel processing of queries using an optimized execution environment and filesystem for high-performance online processing.  A Roxie cluster is similar in its function and capabilities to Hadoop with HBase and Hive capabilities added, and provides for near real time predictable query latencies. Both Thor and Roxie clusters utilize the ECL programming language for implementing applications, increasing continuity and programmer productivity.

Figure 3 shows a representation of a physical Roxie processing cluster which functions as an online query execution engine for high-performance query and data warehousing applications.  A Roxie cluster includes multiple nodes with server and worker processes for processing queries; an additional auxiliary component called an ESP server which provides interfaces for external client access to the cluster; and additional common components which are shared with a Thor cluster in an HPCC environment.  Although a Thor processing cluster can be implemented and used without a Roxie cluster, an HPCC environment which includes a Roxie cluster should also include a Thor cluster.  The Thor cluster is used to build the distributed index files used by the Roxie cluster and to develop online queries which will be deployed with the index files to the Roxie cluster.

== HPCC Software Architecture ==

The HPCC software architecture incorporates the Thor and Roxie clusters as well as common [[Middleware]] components, an external communications layer, client interfaces which provide both end-user services and system management tools, and auxiliary components to support monitoring and to facilitate loading and storing of filesystem data from external sources.  An HPCC environment can include only Thor clusters, or both Thor and Roxie clusters.  The overall HPCC software architecture is shown in Figure 4.{{-}}

[[File:Fig4b HPCC.jpg|thumb|center|Figure 4. HPCC Software Architecture]]

== See also ==

* [[High-Performance Computing]]
* [[Supercomputer]]
* [[Computer cluster]]
* [[COTS]]
* [[List of important publications in concurrent, parallel, and distributed computing]]
* [[Parallel Computing]]
* [[Distributed Computing]]
* [[Parallel programming model]]
* [[Data parallelism]]
* [[Big Data]]
* [[Implicit parallelism]]
* [[Declarative programming]]
* [[Data-intensive computing]]

== References ==
&lt;!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

== External links ==
* [http://www.hpcprojects.com/news/news_story.php?news_id=922 Sandia sees data management challenges spiral]
* [http://www.businesswire.com/news/home/20090728005267/en/Sandia-National-Laboratories-Leverages-Data-Analytics-Supercomputer Sandia National Laboratories Leverages the Data Analytics Supercomputer (DAS) by LexisNexis Risk &amp; Information Analytics Group, Which Offers Breakthrough High Performance Computing to Address Data Management and Analysis Challenges]
* [http://www.lanl.gov/orgs/hpc/salishan/salishan2010/pdfs/John%20Holt.pdf Programming models for the LexisNexis High Performance Computing Cluster]
* [http://www.gtra.org/attachments/567_Data%20Sheet%20-%20LexisNexis%20Data%20Analytics%20Supercomputer.pdf LexisNexis Data Analytics Supercomputer]
* [http://hpccsystems.com LexisNexis HPCC Systems]
* [http://findarticles.com/p/articles/mi_m0EIN/is_2001_Feb_28/ai_70924764/ Reference to the term BORPS (Billions of Records Per Second)]
* [http://www.hpcwire.com/hpcwire/2009-07-23/lexisnexis_brings_its_data_management_magic_to_bear_on_scientific_data.html LexisNexis Brings Its Data Management Magic To Bear on Scientific Data]

&lt;!--- Categories ---&gt;

{{DEFAULTSORT:Hpcc}}
[[Category:Parallel computing]]
[[Category:Distributed computing]]
[[Category:Declarative programming languages]]
[[Category:Query languages]]
[[Category:Data warehousing products]]</text>
      <sha1>ka79ith9df0vuywgludg79ctm4fyjm6</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>