<?xml version="1.0" ?><page xmlns="http://www.mediawiki.org/xml/export-0.8/" version="0.8">
    <title>Greenplum</title>
    <ns>0</ns>
    <id>20294190</id>
    <revision>
      <id>560788964</id>
      <parentid>560788805</parentid>
      <timestamp>2013-06-20T19:02:02Z</timestamp>
      <contributor>
        <ip>115.248.117.90</ip>
      </contributor>
      <comment>/* Shakeel History */</comment>
      <text xml:space="preserve">{{multiple issues|
{{advert|date=July 2012}}
{{Refimprove|date=April 2007}}
}}

{{Infobox company|
  name   = Greenplum  |
  logo   = [[Image:greenplumlogotype.jpg|200px]] |
  type   = Division of [[EMC Corporation]] |
  company_slogan = Driving the future of Big Data analytics |
  foundation     = 2003 |
  location       = [[Image:Flag of the United States.svg|20px]] [[San Mateo, California|San Mateo]], [[California]], [[United States]] |
  key_people     = Bill Cook, President&lt;br /&gt;Scott Yara, SVP of Products &amp; Co-Founder&lt;br /&gt;Luke Lonergan, Co-Founder&lt;br /&gt;David Wittenkamp, Chief Financial Officer&lt;br /&gt;Charles McDevitt, Chief Architect |
  industry       = [[Big Data]] technologies|
  products       = Unfied Analytics Platform (UAP), Database Software, Chorus Software, Enterprise-Ready Hadoop, Data Computing Appliance (DCA), Analytics Labs |
  homepage       = [http://www.greenplum.com/ www.greenplum.com]
}}

'''Greenplum''' is a [[Big Data]] analytics company in [[San Mateo, California|San Mateo]], [[California]]. Greenplum's products include Greenplum Unified Analytics Platform, Greenplum Data Computing Appliance, Greenplum Analytics Lab, Greenplum Database, Greenplum HD and Greenplum Chorus. Greenplum was acquired by [[EMC Corporation|EMC]] in July 2010,&lt;ref name="aquired"&gt;
{{cite web 
| url = http://www.emc.com/about/news/press/2010/20100706-01.htm
| title = EMC to Acquire Greenplum
| publication-date = 2010-07-06
| accessdate  = 2012-07-05
}}
&lt;/ref&gt; becoming the foundation of EMC's Big Data Division.

== Shakeel Owner Greenplum company ==
Timeline information taken from Greenplum company history unless otherwise cited.&lt;ref&gt;{{cite web|title=History|url=http://www.greenplum.com/about-us|work=Greenplum company website|accessdate=7 August 2012}}&lt;/ref&gt; 
* 2003: Founded by Scott Yara and Luke Lonergan &lt;ref&gt;
{{cite web 
| url = http://www.greenplum.com/about-us/management-team
| title = Management Team
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;
* 2005: Greenplum Database Released
* 2006: Sun Partnership
* 2008: Greenplum Map Reduce
* 2010: [[EMC Corporation|EMC]] Acquisition,&lt;ref name="acquired"/&gt; Greenplum Data Computing Appliance Introduced
* 2011: Greenplum Community Edition Released, Greenplum | SAS Strategic Partnership, Greenplum HD (Enterprise-Ready Hadoop) Introduced, First Annual Data Science Summit, MADLib, Modular Greenplum DCA Product Line, Greenplum Unified Analytics Platform UAP Launch
* 2012: Greenplum Chorus released, Second Annual Data Science Summit, Greenplum Analytics Workbench Goes Live
* 2013: Greenplum becomes [[GoPivotal | Pivotal]]&lt;ref&gt;[http://gigaom.com/2013/03/13/the-pivotal-initiative-in-case-you-were-wondering-is-now-official The Pivotal Initiative, in case you were wondering, is now official], 13-May-2013&lt;/ref&gt;

==Technology and Products==

===Greenplum Unified Analytics Platform (UAP)===
The Greenplum UAP solution includes Greenplum Database, Greenplum HD, Greenplum Chorus, Greenplum Command Center, Greenplum DCA and Greenplum Analytics Lab (Data Scientist team).

===Greenplum Database===
The Greenplum Database builds on the foundations of [[open source]] database [[PostgreSQL]].&lt;ref&gt;{{cite web |url=http://intelligent-enterprise.informationweek.com/showArticle.jhtml;jsessionid=3IEDTLRVJ3LDLQE1GHOSKH4ATMY32JVN?articleID=206801311 |title=Greenplum Updates Open-Source Based Database |date=February 22, 2008 |last=Gonsalves |first=Antone}}&lt;/ref&gt; It primarily functions as a [[data warehouse]] and utilizes a [[shared-nothing architecture|shared-nothing]], [[massively parallel (computing)|massively parallel]] processing (MPP) architecture. In this architecture, data is partitioned across multiple segment servers, and each segment owns and manages a distinct portion of the overall data; there is no disk-level sharing nor data contention among segments.

====Parallel query optimizer====
Greenplum Database's parallel [[query optimizer]] is responsible for converting SQL or MapReduce into a physical execution plan.&lt;ref name="mania"&gt;
{{cite web 
| url = http://www.technology-mania.com/2011/04/understanding-greenplum.html
| title = Understanding Greenplum
| accessdate  = August 7, 2012
}}
&lt;/ref&gt; Greenplum's optimizer uses a cost-based optimization algorithm&lt;ref name="mania" /&gt; to evaluate potential execution plans, takes a global view of execution across the cluster, and factors in the cost of moving data between nodes in any candidate plan. The resulting query plans contain traditional physical operations - scans, joins, sorts, aggregations, etc. - as well as parallel "motion" operations that describe when and how data should be transferred between nodes during query execution.
Greenplum Database has three kinds of "motion" operations that may be found in a query plan:
&lt;ref name="manual"&gt;
{{cite web 
| url = http://bitcast-a.v1.sjc1.bitgravity.com/greenplum/Greenplum_CE_Database/documentation/4.2.1.0/greenplum_database_4.2_administrator_guide.pdf
| title = Greenplum Database Release 4.2.1.0 Documentation 
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;
*Broadcast Motion (N:N) - Every segment sends the target data to all other segments
*Redistribute Motion (N:N) - Every segment rehashes the target data (by join column) and redistributes each row to the appropriate segment
*Gather Motion (N:1) - Every segment sends the target data to a single node (usually the master)

Within the execution of each node in the query plan, multiple relational operations are processed by [[Pipeline (computing)|pipelining]]. Pipelining is the ability to begin a task before its predecessor task has completed, and this ability is key to increasing basic query parallelism. For example, while a table scan is taking place, rows selected can be pipelined into a join process.

====gNet Software Interconnect====
In shared-nothing MPP database systems, data often needs to be moved whenever there is a join or an aggregation process for which the data requires repartitioning across the segments. Greenplum’s gNet interconnect optimizes the flow of data to allow continuous pipelining of processing without blocking on all nodes of the system. The gNet interconnect is tuned and optimized to scale to 10,000s of processors and leverages commodity Gigabit Ethernet and 10GigE switch technology. 

The gNet software interconnect is a supercomputing-based ‘soft-switch’ that is responsible for efficiently pumping streams of data between motion nodes during query-plan execution. It delivers messages, moves data, collects results, and coordinates work among the segments in the system. 
&lt;ref&gt;
{{cite web 
| url = http://www.greenplum.com/technology/gnet
| title = gNet Software Interconnect
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

====Parallel Dataflow Engine====
The Parallel Dataflow Engine is an optimized parallel processing infrastructure that is designed to process data as it flows from disk, from external files or applications, or from other segments over the gNet interconnect. The engine is inherently parallel – it spans all segments of a Greenplum Database cluster and can scale effectively to thousands of commodity processing cores. The engine was designed based on supercomputing principles, with the theory that large volumes of data have ‘weight’ (i.e. aren’t easily moved around) and so processing should be pushed as close as possible to the data.&lt;ref&gt;
{{cite web 
| url = http://www.greenplum.com/technology/dataflow
| title = Parallel Dataflow Engine
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

====Multi-level fault tolerance====
Internally, the Greenplum system utilizes log shipping and segment-level replication to achieve redundancy, and provides automated failover. The system also provides multiple levels of redundancy and integrity checking. At the lowest level, Greenplum Database utilizes [[RAID]]-0+1 or RAID-5 storage to detect and mask disk failures. At the system level, Greenplum continuously replicates all segment and master data to other nodes within the system to ensure that the loss of a machine will not impact the overall database availability. Greenplum also utilizes redundant network interfaces on all systems, and specifies redundant switches in all reference configurations.
&lt;ref&gt;
{{cite web 
| url = http://www.greenplum.com/technology/fault-tolerance
| title = Multi-Level Fault Tolerance
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

====MPP Scatter/Gather Streaming technology====
Greenplum’s SG Streaming technology ensures parallelism by 'scattering' data from all source systems across hundreds or thousands of parallel streams that simultaneously flow to all nodes of the Greenplum Database. Performance scales with the number of Greenplum Database nodes, and the technology supports both large batch and continuous near-real-time loading patterns with negligible{{Clarify|date=December 2012}} impact on concurrent database operations. Data can be transformed and processed in-flight, utilizing all nodes of the database in parallel, for high-performance ELT (extract-load-transform) and ETLT (extract-transform-load-transform) loading pipelines. Final 'gathering' and storage of data to disk takes place on all nodes simultaneously, with data automatically partitioned across nodes and optionally compressed. This technology is exposed to the DBA via a programmable "external table" interface and a traditional command-line loading interface.
&lt;ref&gt;
{{cite web 
| url = http://www.zdnet.com/blog/gardner/greenplum-aims-to-eliminate-massive-data-load-choke-points-with-scattergather-technology/2866
| title = Greenplum aims to eliminate massive data load 'choke points' with Scatter/Gather technology
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

====Greenplum MapReduce====
Greenplum execute both MapReduce and SQL directly within Greenplum’s parallel dataflow engine, enabling programmers to run analytics against petabyte-scale datasets stored in and outside of the Greenplum Database. It has the ability to directly execute all necessary SQL building blocks, including performance-critical operations such as hash-join, multi-stage hash-aggregation, SQL 2003 windowing (which is part of the SQL 2003 OLAP extensions that are implemented by Greenplum), and arbitrary MapReduce programs.
&lt;ref&gt;
{{cite web 
| url = http://www.prweb.com/releases/2008/08/prweb1248014.htm
| title = Greenplum Brings MapReduce to the Enterprise 
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

====Polymorphic data storage====
For each table (or partition of a table), the database administrators can select the storage, execution and compression settings that suit the way that table will be accessed. Greenplum DB transparently abstracts the details of any table or partition, allowing a wide variety of underlying models: 
&lt;ref&gt;
{{cite web 
| url = http://www.dbms2.com/2009/10/14/greenplum-hybrid-columnar/
| title = Greenplum is going hybrid columnar as well 
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;
*Read/Write Optimized — Traditional 'slotted page' row-oriented table (based on PostgreSQL's native table type), optimized for fine-grained CRUD operations.
*Row-oriented / Read-Mostly Optimized—Optimized for read-mostly scans and bulk append loads. DDL allows optional compression ranging from fast/light to deep/archival.
*Column-oriented / Read-Mostly Optimized — Added as a feature in Greenplum's latest 3.3.4 release, providing a true column-store just by specifying 'WITH (orientation=column)' on a table. Data is vertically partitioned, and each column is stored in a series of large densely-packed blocks that can be efficiently compressed from fast/light to deep/archival (and tend to see notably higher compression ratios than row-oriented tables). Performance is excellent for those workloads suited to column-store — Greenplum's implementation only scans those columns required by the query, doesn't have the overhead of per-tuple IDs, and does efficient early materialization using an optimized 'columnar append' operator.

When combined with Greenplum's multi-level table partitioning, database administrators can tune the storage types and compression settings of different partitions within the same table. I.e. a single partitioned table could (for example) have older data stored as 'column-oriented with deep/archival compression', more recent data as 'column-oriented with fast/light compression', and the most recent data as 'read/write optimized' to support fast updates and deletes.
&lt;ref&gt;
{{cite web 
| url = http://www.prweb.com/releases/2009/10/prweb3049904.htm
| title = Greenplum Adds Column-Oriented Table Feature to Greenplum Database 
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

===Greenplum Hadoop (HD)===
Greenplum HD is a supported version of the Apache Hadoop stack. It includes [[Apache Hadoop#Hadoop_Distributed_File_System|Hadoop Distributed File System (HDFS)]], [[MapReduce]], [[Apache Hive|Hive]], [[Pig (programming tool)|Pig]], [[HBase]], and [[Apache ZooKeeper|ZooKeeper]]. Greenplum HD’s packaged Hadoop distribution removes the need in building out a Hadoop cluster from scratch, which is required with other distributions. Isilon scale out file system technologies can also be deployed in Greenplum HD Enterprise edition to improve the reliability of Greenplum HD systems.
&lt;ref&gt;
{{cite web 
| url = http://wikibon.org/blog/emc-marries-isilon-with-greenplum-hadoop-distribution-2/
| title = EMC Marries Isilon with Greenplum Hadoop Distribution
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

===Greenplum Chorus===
Greenplum Chorus is a social network portal for the data science team to search, explore, visualize, share, import data from both within the organization and external sources. Furthermore, Chorus utilizes technologies from VMware for data science teams to create virtual "sandbox" for data exploration without the fear of corrupting the data source.
&lt;ref&gt;
{{cite web 
| url = http://www.informationweek.com/news/development/database/232602911
| title = EMC Marries Social Networking And Big Data 
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

===Greenplum Data Computing Appliance (DCA)===
The EMC Greenplum Data Computing Appliance (DCA) is a physical appliance built to integrate structured data, unstructured data, and Greenplum partner applications such as business intelligence (BI), and extract, transform and load (ETL).&lt;ref&gt;
{{cite web 
| url = http://www.theregister.co.uk/2011/09/21/emc_greenplum_dca_appliance_update/
| title = Greenplum appliances swing both ways
| accessdate  = August 7, 2012
}}
&lt;/ref&gt; A special version of DCA with integration of SAS software was released in 2011.
&lt;ref&gt;
{{cite web 
| url = http://www.zdnet.com/blog/btl/emc-greenplum-inks-sas-partnership-launches-new-appliances/46900
| title = EMC Greenplum inks SAS partnership, launches new appliances
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

===Greenplum Command Center===
Greenplum Command Center is a single console with a set of interactive dashboards, enabling administrators to collect performance metrics and manage system health for Greenplum products. Monitored data is also stored for historical reporting. Greenplum Command Center also has data collection agents that run on the Master Server and each Segment Server. The agents collect performance data on query execution and system utilization and send it to the Greenplum Command Center at regular intervals.
&lt;ref&gt;
{{cite web 
| url = http://www.theregister.co.uk/2012/03/01/greenplum_database_4_2/
| title = EMC cranks Greenplum database to 4.2
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

===Greenplum Analytics Lab===
Greenplum Analytics Lab is a data science consultation service provided by Greenplum’s team of data scientists.  Various packages are available depending on client’s budget and requirements. 
&lt;ref&gt;
{{cite web 
|url=http://www.greenplum.com/products/greenplum-analytics-lab
|title=Greenplum Analytics Lab
|accessdate=August 7, 2012}}
&lt;/ref&gt;
*Analytics Lab Primer: 1 day workshop as introduction to Big Data Analytics.
*Analytics Lab 100: 2 week consultation for quick insights, training on analytics methods and tools by a Greenplum Data Scientist.
*Analytics Lab 600: 6 week consultation that extends on Lab 100 and focus on the creation of a ready-do-deploy analytical model and the training and documentation to support future use.
*Analytics Lab 1200: 12 week consultation that extends on Lab 600 for deployment of more complex models.

===Platform support===
*Greenplum Database supported for production use on [[SUSE Linux Enterprise Server]] 10.2 (64-bit), [[Red Hat Enterprise Linux]] 5.x (64-bit), [[CentOS]] Linux 5.x (64-bit) and Sun Solaris 10U5+ (64-bit). Greenplum Database 3.3 is supported on server hardware from a range of vendors including HP, Dell, Sun and IBM.&lt;ref name="manual"/&gt;

*Greenplum Database is supported for non-production (development and evaluation) use on Mac OSX 10.5, Red Hat Enterprise Linux 5.2 or higher (32-bit) and CentOS Linux 5.2 or higher (32-bit).&lt;ref&gt;
{{cite web 
| url = http://www.greenplum.com/products/community-edition/
| title = Greenplum Database: Community Edition
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

==Customers==
Greenplum has over 500 customers in [[Vertical market|vertical]]s from financial services, telecommunications, Internet, retail, transportation and pharmaceuticals industries.
,&lt;ref&gt;
{{cite web 
| url = http://www.dbms2.com/2009/04/30/ebays-two-enormous-data-warehouses/
| title = ebay's two enormous data warehouses
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;  Greenplum customers include [[Silver Spring Networks]], [[Zions Bancorporation]], [[Reliance Communications]], [[NYSE Euronext]], [[Bakrie Telecom]], [[Orbitz]], [[Havas Digital]], [[China Unicom]], [[ClickFox]], [[Frank Templeton Investments]]  and [[Tagged]].
&lt;ref&gt;
{{cite web 
| url = http://www.greenplum.com/customers/our-customers/
| title = Our Customers
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

==Community Edition==
Like many other enterprise software, Greenplum also provides a community edition of its "cutting edge" database,&lt;ref&gt;{{cite web|title=Greenplum DB Community Edition|url=http://www.greenplum.com/products/community-edition/}}&lt;/ref&gt; as well as community forums.&lt;ref&gt;{{cite web|title=Greenplum Communities|url=http://www.greenplum.com/communities/}}&lt;/ref&gt; However the community forums are very poorly supported in comparison with MySQL communities.&lt;ref&gt;{{cite web|title=MySQL Community Forum|url=http://forums.mysql.com/}}&lt;/ref&gt;

==Criticism==
Greenplum DB has a limitation on indexing: Unique index and primary key index cannot be used at same time on a table.&lt;ref&gt;{{cite web|title=Greenplum db - may not be as ready as you think|url=http://it.toolbox.com/blogs/sap-on-db2/greenplum-db-may-not-be-as-ready-as-you-think-51834}}&lt;/ref&gt;

==Partnerships==
They include [[XBRLWorks]],&lt;ref&gt;{{cite web|title=XBRLWorks - Data Science Partners|url=http://datascienceseries.com/partners/partners/xbrl-works}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=XBRLWorks|url=http://www.xbrlworks.com/}}&lt;/ref&gt; [[Cisco]], [[Brocade Communications Systems]], [[SAS (software)]], [[Factual]], [[Alpine Data Labs]], [[MicroStrategy]], and [[Informatica]].&lt;ref&gt;{{cite web |url=http://www.greenplum.com/partners/greenplum-partners |title=Greenplum Partners |accessdate=October 29, 2010}}&lt;/ref&gt;

==Competition==
Greenplum's main competitors are vendors such as [[IBM]], [[Exadata|Oracle Exadata]], [[Teradata]], [[Netezza]], [[SAP AG|SAP]], and [[Vertica]].
&lt;ref&gt;
{{cite web 
| url = http://www.gartner.com/technology/reprints.do?id=1-196T8S5&amp;ct=120207&amp;st=sb
| title = Magic Quadrant for Data Warehouse Database Management Systems
| accessdate  = August 7, 2012
}}
&lt;/ref&gt;

== See also ==

* [[Column-oriented database]]
* [[Vertica]]
* [[MapReduce]]
* [[Sybase IQ]]

==References==
{{reflist}}

==External links==
* [http://www.greenplum.com/ Company Home page]

{{EMC}}

[[Category:Business intelligence]]
[[Category:Data warehousing products]]
[[Category:Big Data]]</text>
      <sha1>3bj69xc4afn20k43tn762zs4lezvyh8</sha1>
      <model>wikitext</model>
      <format>text/x-wiki</format>
    </revision>
  </page>